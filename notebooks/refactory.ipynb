{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a392d47-9645-412f-a320-2b23a2410332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.data import Dataset, DataLoader\n",
    "from models import SelfAttention, HybridModel\n",
    "from tqdm import tqdm \n",
    "import wandb\n",
    "\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58477e77-27ae-486e-84d4-40e9f2be11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def get_hash(x):\n",
    "  return hashlib.sha1(x.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c08ada-8575-4fb1-8402-96cf6f02be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading graphs: 100%|█████████████████████████████████████████████████████████████████| 24607/24607 [00:07<00:00, 3461.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24607 graphs.\n",
      "24603 23339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the directory where your files are located\n",
    "directory = 'D:\\Edward\\Smita_Lab_Work\\PyGs\\PyGs'\n",
    "\n",
    "# Get a list of all .pt files in the directory\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.pt')]\n",
    "\n",
    "# Initialize an empty list to store the graphs\n",
    "graphs = []\n",
    "\n",
    "# Loop through the files and load each graph, showing a progress bar\n",
    "for file in tqdm(files, desc=\"Loading graphs\"):\n",
    "    file_path = os.path.join(directory, file)\n",
    "    graph = torch.load(file_path)\n",
    "    graphs.append(graph)\n",
    "\n",
    "# Now `graphs` contains all the loaded graph objects\n",
    "print(f\"Loaded {len(graphs)} graphs.\")\n",
    "\n",
    "\n",
    "graphs = [x for x in graphs if ('NXVPMVATV' not in x.name) and ('X' not in x.name)]\n",
    "\n",
    "strings = [x.name.split(\"Immuno\")[1] for x in graphs]\n",
    "\n",
    "print(len(strings), len(set(strings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbff5a86-2f14-4859-8704-498206dbf5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23339 23339\n"
     ]
    }
   ],
   "source": [
    "new_graphs = []\n",
    "names = set()\n",
    "\n",
    "for graph in graphs:\n",
    "    if graph.name.split(\"Immuno\")[1] not in names:\n",
    "        names.add(graph.name.split(\"Immuno\")[1])\n",
    "        new_graphs.append(graph)\n",
    "\n",
    "strings = [x.name.split(\"Immuno\")[1] for x in new_graphs]\n",
    "\n",
    "print(len(strings), len(set(strings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48ac77b-355e-439e-96ba-360ce08f7fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element Count\n",
      "PKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRRVLSFIKGTK_29174    1\n",
      "PRTHMTHHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWASVVVPSGQEQRYTCHVQHEGLPKPLTLRIVQKAPIYKR_9ef65    1\n",
      "PRTHMTHHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWASVVVPSGQEQRYTCHVQHEGLPKPLTLRIVNKFMSFYK_ea184    1\n",
      "PRTHMTHHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWASVVVPSGQEQRYTCHVQHEGLPKPLTLRIVMPVFIIKR_d3bdf    1\n",
      "PRTHMTHHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWASVVVPSGQEQRYTCHVQHEGLPKPLTLRIVLLFPSIIY_f638d    1\n",
      "                                                                                                            ..\n",
      "PPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRNTYGEGFDY_8d6bf    1\n",
      "PPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRNTYGEGFDY_4ef5f    1\n",
      "PPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRNTYASPRFK_95a70    1\n",
      "PPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRNTWKPELPK_aa5fb    1\n",
      "APKTHMTHHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGQEQRYTCHVQHEGLPKPLTLRAAPAHSHAG_0d580    1\n",
      "Name: count, Length: 23339, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = pd.Series(strings).value_counts()\n",
    "print(\"Element Count\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e90d03-36ad-40bf-b207-a070b94e51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = pd.read_table('D:\\Edward\\Smita_Lab_Work\\complete_score_Mprops_1_2.csv')\n",
    "expanded_df = expanded_df.dropna(subset='Foreignness_Score')\n",
    "expanded_df['pep_pair'] = expanded_df['peptide'] + expanded_df['allele']\n",
    "\n",
    "f_dict = dict(zip(expanded_df['pep_pair'],expanded_df['smoothed_foreign']))\n",
    "fp2_dict = dict(zip(expanded_df['pep_pair'],expanded_df['Mprop1']))\n",
    "new_imm_dict = dict(zip(expanded_df['pep_pair'],expanded_df['immunogenicity']))\n",
    "\n",
    "expanded_pep_pair = expanded_df['pep_pair'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c61664-b9a3-4f7b-85a9-c50a18820e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24539\n"
     ]
    }
   ],
   "source": [
    "print(len(expanded_pep_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186ec306-994f-417c-952a-bb3c951f3489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LSNSGKDVPKHLA-A*11:01',\n",
       " 'TTLFHTFYELHLA-A*24:02',\n",
       " 'KFGDLTNNFHLA-A*24:02',\n",
       " 'KLFESKAELHLA-A*02:01']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_pep_pair[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4c1319-164e-4862-810c-d0a8938f1280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "#cut off h-bonding features for now \n",
    "\n",
    "for data in graphs:  # Assuming data_list is the list containing your graph data\n",
    "    data.x = data.x[:, :-2]\n",
    "\n",
    "hla_df = pd.read_csv('D:\\Edward\\Smita_Lab_Work\\HLA_27_seqs_csv.csv')\n",
    "hla_dict_true = dict(zip(hla_df['allele'], hla_df['seqs']))\n",
    "print(len(hla_dict_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05518b3-e7cb-4252-80ce-84facca19f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24539 24539\n",
      "[('SHSMRYFYTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDQETRNVKAQSQTDRVDLGTLRGYYNQSEDGSHTIQIMYGCDVGPDGRFLRGYRQDAYDGKDYIALNEDLRSWTAADMAAQITKRKWEAAHAAEQQRAYLEGRCVEWLRRYLENGKETLQRTDPPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRLSNSGKDVPK', 'PKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRLSNSGKDVPK_601a6', 'LSNSGKDVPK'), ('SHSMRYFSTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDEETGKVKAHSQTDRENLRIALRYYNQSEAGSHTLQMMFGCDVGSDGRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQITKRKWEAAHVAEQQRAYLEGTCVDGLRRYLENGKETLQRTDPPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRTTLFHTFYEL', 'PKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRTTLFHTFYEL_36be2', 'TTLFHTFYEL'), ('SHSMRYFSTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDEETGKVKAHSQTDRENLRIALRYYNQSEAGSHTLQMMFGCDVGSDGRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQITKRKWEAAHVAEQQRAYLEGTCVDGLRRYLENGKETLQRTDPPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRKFGDLTNNF', 'PPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRKFGDLTNNF_f1efe', 'KFGDLTNNF')]\n"
     ]
    }
   ],
   "source": [
    "name_mapper = {} # pep_pair: actual sequence, name in pyG\n",
    "\n",
    "for seq in expanded_pep_pair:\n",
    "    pep, hla = seq.split(\"HLA-\")\n",
    "    unfolded = hla_dict_true[\"HLA-\"+hla]\n",
    "    name = unfolded + pep\n",
    "    hashed = get_hash(name)[:5]\n",
    "    name_mapper[seq] = (name, name[-99:]+\"_\"+hashed, pep)\n",
    "print(len(name_mapper), len(set(name_mapper.keys())))\n",
    "print(list(name_mapper.values())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d481e6a6-9517-4044-ac5b-0119841294a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23339\n",
      "23339\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# make both table and graphs size 1:1\n",
    "\n",
    "# graph -> table\n",
    "strings = [x.name.split(\"Immuno\")[1] for x in new_graphs]\n",
    "names = set(strings)\n",
    "to_remove = []\n",
    "for x, y in name_mapper.items():\n",
    "    if y[1] not in names:\n",
    "        to_remove.append(x)\n",
    "\n",
    "for i in to_remove:\n",
    "    del name_mapper[i]\n",
    "\n",
    "print(len(name_mapper))\n",
    "\n",
    "# table -> graph\n",
    "to_remove = set()\n",
    "mapper_names = set(y[1] for x, y in name_mapper.items())\n",
    "\n",
    "for i in strings:\n",
    "    if i not in mapper_names:\n",
    "        to_remove.add(i)\n",
    "\n",
    "new_graphs = [x for x in new_graphs if x.name.split(\"Immuno\")[1] not in to_remove]\n",
    "strings = [x for x in new_graphs]\n",
    "print(len(strings))\n",
    "print(len(to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222118e7-7188-4033-af46-369257c6fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23339\n"
     ]
    }
   ],
   "source": [
    "graph_mapper = {x.name.split(\"Immuno\")[1]: x for x in new_graphs}\n",
    "print(len(graph_mapper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bed06d5-e562-44ca-865c-f83bbbcb568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in name_mapper.items():\n",
    "    \n",
    "    immuno_score = new_imm_dict[x]\n",
    "    f_score = f_dict[x]\n",
    "    graph = graph_mapper[y[1]]\n",
    "\n",
    "    \n",
    "    graph.y = torch.tensor([immuno_score, f_score], dtype=torch.float)  # We use a one-element tensor for each graph-level label\n",
    "    graph.x = torch.cat([graph.x, graph.coords], dim=-1)\n",
    "\n",
    "    graph.x = graph.x.to(dtype=torch.float32)\n",
    "    graph.y = graph.y.to(dtype=torch.float32)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecbca02e-0187-48b6-9054-371a70372312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_graph(graph, max_nodes, feature_size, coord_size):\n",
    "    num_nodes_to_add = max_nodes - graph.num_nodes\n",
    "    if num_nodes_to_add > 0:\n",
    "        # Pad node features\n",
    "        zero_features = torch.zeros(num_nodes_to_add, feature_size)\n",
    "        padded_features = torch.cat([graph.x, zero_features], dim=0)\n",
    "\n",
    "        # Pad coordinates\n",
    "        zero_coords = torch.zeros(num_nodes_to_add, coord_size)\n",
    "        padded_coords = torch.cat([graph.coords, zero_coords], dim=0)\n",
    "\n",
    "        # Update the graph\n",
    "        graph.x = padded_features\n",
    "        graph.coords = padded_coords\n",
    "        graph.num_nodes = max_nodes\n",
    "    return graph\n",
    "\n",
    "max_nodes = max(graph.num_nodes for graph in graph_mapper.values())\n",
    "feature_size = 23  # Replace with the size of your feature vectors\n",
    "coord_size = 3     # Replace with the size of your coordinate vectors\n",
    "\n",
    "padded_graphs = {name: pad_graph(graph, max_nodes, feature_size, coord_size) for name, graph in graph_mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef0b0c16-426d-416c-89dd-0ca00aab677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dgl(pt_geometric_graph):\n",
    "     # The number of edges is half the size of the second dimension of edge_index\n",
    "    num_edges = pt_geometric_graph.edge_index.size(1)\n",
    "    \n",
    "    # Create a tensor of ones with the size equal to the number of edges\n",
    "    # Assuming all edges have a single feature, which is set to 1\n",
    "    pt_geometric_graph.edge_attr = torch.ones((num_edges, 1))\n",
    "\n",
    "    # Convert to DGL graph\n",
    "    src, dst = pt_geometric_graph.edge_index\n",
    "    dgl_graph = dgl.graph((src, dst), num_nodes=pt_geometric_graph.num_nodes)\n",
    "    dgl_graph.ndata['x'] = pt_geometric_graph.x  # Node features\n",
    "    dgl_graph.edata['edge_attr'] = pt_geometric_graph.edge_attr  # Edge attributes\n",
    "    return dgl_graph\n",
    "\n",
    "graph_mapper = {name: to_dgl(graph) for name, graph in padded_graphs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68844d8-6bed-4e5a-b945-492f166c174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "print(max(len(y[0]) for x, y in name_mapper.items()))\n",
    "print(min(len(y[0]) for x, y in name_mapper.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a93cd0c2-6f40-4560-9482-2a6566a51712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad peptide sequences\n",
    "def pad_peptide_sequence(sequence, max_length=11, padding_char='J'):\n",
    "    # Pad the sequence with the padding character to reach the max length\n",
    "    padded_sequence = sequence.ljust(max_length, padding_char)\n",
    "    return padded_sequence\n",
    "\n",
    "name_mapper = {x:(pad_peptide_sequence(a, 283), b, pad_peptide_sequence(c)) for x, (a, b, c) in name_mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f8e5bf-3f22-49bf-9be5-dc2e9ea09bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peptide\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_sequence(sequence, amino_acids = 'ACDEFGHIKLMNPQRSTVWY', padding_char='J'):\n",
    "    # Create a dictionary mapping each amino acid and padding character to an integer\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(amino_acids + padding_char))\n",
    "\n",
    "    # Initialize the one-hot encoded matrix for the sequence\n",
    "    one_hot_encoded = np.zeros((len(sequence), len(char_to_int)))\n",
    "\n",
    "    # Fill the one-hot encoded matrix with appropriate values\n",
    "    for i, char in enumerate(sequence):\n",
    "        if char in char_to_int:  # Only encode known characters\n",
    "            one_hot_encoded[i, char_to_int[char]] = 1\n",
    "        else:\n",
    "            print(\"unknown character: {}\", char)\n",
    "    \n",
    "    return one_hot_encoded\n",
    "\n",
    "encoded_full_sequence_map = {x:one_hot_encode_sequence(a) for x, (a, b, c) in name_mapper.items()}\n",
    "print(\"peptide\")\n",
    "encoded_peptide_map = {x:one_hot_encode_sequence(c) for x, (a, b, c) in name_mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21078579-0c90-44d9-b56f-e210816638ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [(x, a, b, c) for x, (a, b, c) in name_mapper.items()]\n",
    "\n",
    "encoded_full_sequence = [encoded_full_sequence_map[x[0]] for x in names]\n",
    "encoded_peptide_sequence = [encoded_peptide_map[x[0]] for x in names]\n",
    "\n",
    "protein_reg_values = [fp2_dict[x[0]] for x in names]\n",
    "protein_immuno_values = [new_imm_dict[x[0]] for x in names]\n",
    "protein_reg_values_f = [f_dict[x[0]] for x in names]\n",
    "\n",
    "dgl_filtered_graphs = [graph_mapper[x[2]] for x in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acd76a52-6d56-456d-9226-cb106737438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# TO CHECK\n",
    "to_remove = set()\n",
    "cache = dict()\n",
    "dupe = 0\n",
    "double_dupe = 0 \n",
    "\n",
    "for n, (a, b, c, d) in enumerate(zip(encoded_full_sequence, protein_reg_values, protein_immuno_values, protein_reg_values_f)):\n",
    "    overlap = (tuple(map(tuple, a)), b, c , d)\n",
    "    if overlap in cache:\n",
    "        dupe+=1\n",
    "        if (dgl_filtered_graphs[cache[overlap]].num_nodes() == dgl_filtered_graphs[n].num_nodes() and \n",
    "            dgl_filtered_graphs[cache[overlap]].num_edges() == dgl_filtered_graphs[n].num_edges() and \n",
    "            dgl_filtered_graphs[cache[overlap]].ndata['x'].tolist() == dgl_filtered_graphs[n].ndata['x'].tolist() and \n",
    "            dgl_filtered_graphs[cache[overlap]].edata['edge_attr'].tolist() == dgl_filtered_graphs[n].edata['edge_attr'].tolist() and \n",
    "            dgl_filtered_graphs[cache[overlap]].edges()[0].tolist() == dgl_filtered_graphs[n].edges()[0].tolist()):\n",
    "            double_dupe+=1\n",
    "            to_remove.add(n)\n",
    "    else:\n",
    "        cache[overlap] = n\n",
    "print(dupe, double_dupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33b4352f-73ce-4ad7-94d7-a6330ec11270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dupes 0 0\n"
     ]
    }
   ],
   "source": [
    "# TO CHECK\n",
    "to_remove = set()\n",
    "cache = dict()\n",
    "dupe = 0\n",
    "double_dupe = 0 \n",
    "\n",
    "for n, (a, b) in enumerate(zip(encoded_full_sequence, protein_reg_values)):\n",
    "    overlap = (tuple(map(tuple, a)), b)\n",
    "    if overlap in cache:\n",
    "        dupe+=1\n",
    "        if (dgl_filtered_graphs[cache[overlap]].num_nodes() == dgl_filtered_graphs[n].num_nodes() and \n",
    "            dgl_filtered_graphs[cache[overlap]].num_edges() == dgl_filtered_graphs[n].num_edges() and \n",
    "            dgl_filtered_graphs[cache[overlap]].ndata['x'].tolist() == dgl_filtered_graphs[n].ndata['x'].tolist() and \n",
    "            dgl_filtered_graphs[cache[overlap]].edata['edge_attr'].tolist() == dgl_filtered_graphs[n].edata['edge_attr'].tolist() and \n",
    "            dgl_filtered_graphs[cache[overlap]].edges()[0].tolist() == dgl_filtered_graphs[n].edges()[0].tolist()):\n",
    "            double_dupe+=1\n",
    "            to_remove.add(n)\n",
    "    else:\n",
    "        cache[overlap] = n\n",
    "print(\"dupes\", dupe, double_dupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ccab4-c13f-4df7-a521-e3c22bfc373e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
